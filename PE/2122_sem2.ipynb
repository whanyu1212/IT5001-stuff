{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Part 1 Name Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterative way\n",
    "def common_char_i(name1:str,name2:str) -> int:\n",
    "    if not name1 or not name2:\n",
    "        return 0\n",
    "    counter = 0\n",
    "    for i in range(min(len(name1),len(name2))):\n",
    "        if name1[i].lower() == name2[i].lower():\n",
    "            counter += 1\n",
    "    return counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert common_char_i('Mark','Mary') == 3\n",
    "assert common_char_i('Brandy','Flank') == 2\n",
    "assert common_char_i('Larry','Clark') == 1\n",
    "assert common_char_i('Teddy','Andy') == 1\n",
    "assert common_char_i('McDonald','Andrey') == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive way\n",
    "def common_char_r(name1:str,name2: str)-> int:\n",
    "    if not name1 or not name2:\n",
    "        return 0\n",
    "    if name1[0].lower() == name2[0].lower():\n",
    "        return 1 + common_char_r(name1[1:],name2[1:])\n",
    "    else:\n",
    "        return common_char_r(name1[1:],name2[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert common_char_r('Mark','Mary') == 3\n",
    "assert common_char_r('Brandy','Flank') == 2\n",
    "assert common_char_r('Larry','Clark') == 1\n",
    "assert common_char_r('Teddy','Andy') == 1\n",
    "assert common_char_r('McDonald','Andrey') == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one line solution\n",
    "def common_char_u(name1: str,name2: str) -> int:\n",
    "    # notice how zip creates an iterable of tuples\n",
    "    return sum(1 for i, j in list(zip('Mark','Mary')) if i.lower() == j.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (3, 4), (5, 6)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: u need to map the zip to a collection to iterate through it\n",
    "list(zip([1,3,5],[2,4,6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Part 2: Text Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'To be or not to be'\n",
    "text3 = 'Do you wish me a good morning or mean that it is a good morning whether I want not or that you feel good this morning or that it is morning to be good on'\n",
    "text7 = 'Text compression will save the world from inefficiency Inefficiency is a blight on the world and its humanity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_compression(text: str) -> str:\n",
    "    if not text:\n",
    "        return ''\n",
    "    if len(text) == 1:\n",
    "        return text.capitalize()\n",
    "    else:\n",
    "        \n",
    "        lst = text.lower().split()\n",
    "\n",
    "        output = []\n",
    "        seen = {}\n",
    "        for i in range(len(lst)):\n",
    "            if lst[i] not in seen or len(lst[i]) == 1:\n",
    "                output.append(lst[i])\n",
    "                seen[lst[i]] = i\n",
    "            else:\n",
    "                output.append(str(seen[lst[i]]+1))\n",
    "        # handle i using list comprehension\n",
    "        output_cap = [i.capitalize() if i == 'i' else i for i in output]\n",
    "        # cap the first word\n",
    "        output_cap[0] = output_cap[0].capitalize()\n",
    "        return ' '.join(output_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text compression will save the world from inefficiency 8 is a blight on 5 6 and its humanity\n",
      "To be or not 1 2\n",
      "Do you wish me a good morning or mean that it is a 6 7 whether I want not 8 10 2 feel 6 this 7 8 10 11 12 7 to be 6 on\n"
     ]
    }
   ],
   "source": [
    "print(text_compression(text7))\n",
    "print(text_compression(text2))\n",
    "print(text_compression(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "part0 = ['   ###   ',\n",
    "'  #   #  ',\n",
    "' #     # ',\n",
    "' #     # ',\n",
    "' #     # ',\n",
    "'  #   #  ',\n",
    "'   ###   ']\n",
    "\n",
    "pic = [[' ', '#', '#', '#', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' '], [' ', '#', '#', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', ' '], [' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', '#', '#', ' '], [' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' '], [' ', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', ' ', '#', ' ', ' '], [' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' '], [' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', '#', '#', ' '], [' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', ' ']]\n",
    "pic1 = [['.', '.', '.', '.', '.', '.', '.', '.', '.', '.'], ['.', '.', '#', '.', '#', '.', '.', '.', '.', '.'], ['.', '.', '.', '#', '.', '.', '.', '.', '.', '.'], ['.', '.', '#', '.', '#', '.', '#', '.', '.', '.'], ['.', '.', '.', '.', '.', '#', '.', '.', '.', '.'], ['.', '.', '.', '.', '#', '.', '#', '.', '.', '.'], ['.', '.', '.', '.', '.', '.', '.', '.', '.', '.']]\n",
    "part1 = ['#.#','.#.','#.#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#.#\n",
      ".#.\n",
      "#.#\n"
     ]
    }
   ],
   "source": [
    "for i in part1:\n",
    "    print(''.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 10\n"
     ]
    }
   ],
   "source": [
    "print(len(pic1),len(pic1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "..#.#.....\n",
      "...#......\n",
      "..#.#.#...\n",
      ".....#....\n",
      "....#.#...\n",
      "..........\n"
     ]
    }
   ],
   "source": [
    "for i in pic1:\n",
    "    print(''.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_matching(pic: list, part: list) -> list:\n",
    "    \n",
    "    # rows and cols of pic1 and part1\n",
    "    # the range to iterate over pic1 and part1\n",
    "    pic_rows, pic_cols = len(pic), len(pic[0])\n",
    "    part_rows, part_cols = len(part), len(part[0])\n",
    "    matches = []\n",
    "\n",
    "    # iterate over all possible starting positions of part1 in pic1 that it can fit\n",
    "    for r in range(pic_rows - part_rows + 1):\n",
    "        for c in range(pic_cols - part_cols + 1):\n",
    "            \n",
    "            match = True\n",
    "            for i in range(part_rows):\n",
    "                for j in range(part_cols):\n",
    "                    if pic[r + i][c + j] != part[i][j]:\n",
    "                        match = False\n",
    "                        break\n",
    "                if not match:\n",
    "                    break\n",
    "            if match:\n",
    "                # Calculate the indices of the match area\n",
    "                smallest_row = r\n",
    "                smallest_col = c\n",
    "                largest_row = r + part_rows -1\n",
    "                largest_col = c + part_cols -1\n",
    "                matches.append((smallest_row, smallest_col, largest_row, largest_col))\n",
    "\n",
    "    return matches\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(map_data: list):\n",
    "    graph = {}\n",
    "    for line in map_data:\n",
    "        locations = line.split()\n",
    "        if len(locations) >= 2:\n",
    "            start, *rest = locations  # Get the first element as start and the rest as destinations\n",
    "            if start not in graph:\n",
    "                graph[start] = []\n",
    "            graph[start].extend(rest)  # Add destinations to the graph\n",
    "    return graph\n",
    "\n",
    "def find_paths_dfs(graph, current, goal, visited, path, paths):\n",
    "    visited.add(current)\n",
    "    path.append(current)\n",
    "\n",
    "    if current == goal:\n",
    "        paths.append(path.copy())\n",
    "    else:\n",
    "        for neighbor in graph.get(current, []):\n",
    "            for neighbor in graph.get(current, []):\n",
    "                if neighbor in path:\n",
    "                    # Backtrack by removing the current node from the path\n",
    "                    path.pop()\n",
    "                else:\n",
    "                    # Recursively explore the neighbor\n",
    "                    find_paths_dfs(graph, neighbor, goal, visited, path, paths)\n",
    "\n",
    "\n",
    "\n",
    "def strategic_count(mapfile:str, start_location:str='CountryA', goal_location:str='capitalB'):\n",
    "    with open(mapfile, 'r') as file:\n",
    "        map_data =  [line.strip() for line in file] # this will contain a list of all the lines in the file\n",
    "    \n",
    "    graph = build_graph(map_data)\n",
    "    visited = set()\n",
    "    paths, path = [], [] # how to get to the goal\n",
    "    find_paths_dfs(graph, start_location, goal_location, visited, path, paths)\n",
    "    \n",
    "    \n",
    "    if paths:\n",
    "        return len(paths)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# def find_paths_bfs(graph, start, goal):\n",
    "#     queue = deque([(start, [start])]) \n",
    "#     paths = []  # List to store valid paths\n",
    "\n",
    "#     while queue:\n",
    "#         print(f\"current path: {queue}\")\n",
    "#         current, path = queue.popleft()  # Dequeue the next node and its path\n",
    "#         print(f\"current node: {current}, current path: {path}\")\n",
    "#         for neighbor in graph.get(current, []):\n",
    "#             if neighbor == goal:\n",
    "#                 paths.append(path + [neighbor])  # Found a valid path\n",
    "#                 print(f\"found a path: {paths}\")\n",
    "#             else:\n",
    "#                 queue.append((neighbor, path + [neighbor]))  # Add neighbors to the queue with updated paths\n",
    "#                 print(f\"add to queue: {queue}\\n\")\n",
    "\n",
    "#     return paths\n",
    "def build_graph(map_data: list):\n",
    "    graph = {}\n",
    "    for line in map_data:\n",
    "        locations = line.split()\n",
    "        if len(locations) >= 2:\n",
    "            start, *rest = locations  # Get the first element as start and the rest as destinations\n",
    "            if start not in graph:\n",
    "                graph[start] = []\n",
    "            graph[start].extend(rest)  # Add destinations to the graph\n",
    "    return graph\n",
    "\n",
    "def find_paths_bfs(graph, start, goal):\n",
    "    queue = [(start, [start])]  # Use a list instead of a deque\n",
    "    paths = []  # List to store valid paths\n",
    "\n",
    "    while queue:\n",
    "        print(f\"current path: {queue}\")\n",
    "        current, path = queue.pop(0)  # Dequeue the first node and its path using pop(0)\n",
    "        print(f\"current node: {current}, current path: {path}\")\n",
    "        for neighbor in graph.get(current, []):\n",
    "            if neighbor == goal:\n",
    "                paths.append(path + [neighbor])  # Found a valid path\n",
    "                print(f\"found a path: {paths}\")\n",
    "            else:\n",
    "                queue.append((neighbor, path + [neighbor]))  # Add neighbors to the queue with updated paths\n",
    "                print(f\"add to queue: {queue}\\n\")\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def strategic_count(mapfile: str, start_location: str = 'CountryA', goal_location: str = 'capitalB'):\n",
    "    with open(mapfile, 'r') as file:\n",
    "        map_data = [line.strip() for line in file]\n",
    "\n",
    "    graph = build_graph(map_data)\n",
    "    paths = find_paths_bfs(graph, start_location, goal_location)\n",
    "\n",
    "    return len(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path: [('CountryA', ['CountryA'])]\n",
      "current node: CountryA, current path: ['CountryA']\n",
      "add to queue: [('VillageA', ['CountryA', 'VillageA'])]\n",
      "\n",
      "add to queue: [('VillageA', ['CountryA', 'VillageA']), ('IntersectionB', ['CountryA', 'IntersectionB'])]\n",
      "\n",
      "add to queue: [('VillageA', ['CountryA', 'VillageA']), ('IntersectionB', ['CountryA', 'IntersectionB']), ('StationC', ['CountryA', 'StationC'])]\n",
      "\n",
      "current path: [('VillageA', ['CountryA', 'VillageA']), ('IntersectionB', ['CountryA', 'IntersectionB']), ('StationC', ['CountryA', 'StationC'])]\n",
      "current node: VillageA, current path: ['CountryA', 'VillageA']\n",
      "add to queue: [('IntersectionB', ['CountryA', 'IntersectionB']), ('StationC', ['CountryA', 'StationC']), ('BuildingD', ['CountryA', 'VillageA', 'BuildingD'])]\n",
      "\n",
      "add to queue: [('IntersectionB', ['CountryA', 'IntersectionB']), ('StationC', ['CountryA', 'StationC']), ('BuildingD', ['CountryA', 'VillageA', 'BuildingD']), ('TowerE', ['CountryA', 'VillageA', 'TowerE'])]\n",
      "\n",
      "current path: [('IntersectionB', ['CountryA', 'IntersectionB']), ('StationC', ['CountryA', 'StationC']), ('BuildingD', ['CountryA', 'VillageA', 'BuildingD']), ('TowerE', ['CountryA', 'VillageA', 'TowerE'])]\n",
      "current node: IntersectionB, current path: ['CountryA', 'IntersectionB']\n",
      "add to queue: [('StationC', ['CountryA', 'StationC']), ('BuildingD', ['CountryA', 'VillageA', 'BuildingD']), ('TowerE', ['CountryA', 'VillageA', 'TowerE']), ('TowerE', ['CountryA', 'IntersectionB', 'TowerE'])]\n",
      "\n",
      "add to queue: [('StationC', ['CountryA', 'StationC']), ('BuildingD', ['CountryA', 'VillageA', 'BuildingD']), ('TowerE', ['CountryA', 'VillageA', 'TowerE']), ('TowerE', ['CountryA', 'IntersectionB', 'TowerE']), ('BuildingD', ['CountryA', 'IntersectionB', 'BuildingD'])]\n",
      "\n",
      "current path: [('StationC', ['CountryA', 'StationC']), ('BuildingD', ['CountryA', 'VillageA', 'BuildingD']), ('TowerE', ['CountryA', 'VillageA', 'TowerE']), ('TowerE', ['CountryA', 'IntersectionB', 'TowerE']), ('BuildingD', ['CountryA', 'IntersectionB', 'BuildingD'])]\n",
      "current node: StationC, current path: ['CountryA', 'StationC']\n",
      "add to queue: [('BuildingD', ['CountryA', 'VillageA', 'BuildingD']), ('TowerE', ['CountryA', 'VillageA', 'TowerE']), ('TowerE', ['CountryA', 'IntersectionB', 'TowerE']), ('BuildingD', ['CountryA', 'IntersectionB', 'BuildingD']), ('deadend', ['CountryA', 'StationC', 'deadend'])]\n",
      "\n",
      "current path: [('BuildingD', ['CountryA', 'VillageA', 'BuildingD']), ('TowerE', ['CountryA', 'VillageA', 'TowerE']), ('TowerE', ['CountryA', 'IntersectionB', 'TowerE']), ('BuildingD', ['CountryA', 'IntersectionB', 'BuildingD']), ('deadend', ['CountryA', 'StationC', 'deadend'])]\n",
      "current node: BuildingD, current path: ['CountryA', 'VillageA', 'BuildingD']\n",
      "found a path: [['CountryA', 'VillageA', 'BuildingD', 'capitalB']]\n",
      "current path: [('TowerE', ['CountryA', 'VillageA', 'TowerE']), ('TowerE', ['CountryA', 'IntersectionB', 'TowerE']), ('BuildingD', ['CountryA', 'IntersectionB', 'BuildingD']), ('deadend', ['CountryA', 'StationC', 'deadend'])]\n",
      "current node: TowerE, current path: ['CountryA', 'VillageA', 'TowerE']\n",
      "found a path: [['CountryA', 'VillageA', 'BuildingD', 'capitalB'], ['CountryA', 'VillageA', 'TowerE', 'capitalB']]\n",
      "current path: [('TowerE', ['CountryA', 'IntersectionB', 'TowerE']), ('BuildingD', ['CountryA', 'IntersectionB', 'BuildingD']), ('deadend', ['CountryA', 'StationC', 'deadend'])]\n",
      "current node: TowerE, current path: ['CountryA', 'IntersectionB', 'TowerE']\n",
      "found a path: [['CountryA', 'VillageA', 'BuildingD', 'capitalB'], ['CountryA', 'VillageA', 'TowerE', 'capitalB'], ['CountryA', 'IntersectionB', 'TowerE', 'capitalB']]\n",
      "current path: [('BuildingD', ['CountryA', 'IntersectionB', 'BuildingD']), ('deadend', ['CountryA', 'StationC', 'deadend'])]\n",
      "current node: BuildingD, current path: ['CountryA', 'IntersectionB', 'BuildingD']\n",
      "found a path: [['CountryA', 'VillageA', 'BuildingD', 'capitalB'], ['CountryA', 'VillageA', 'TowerE', 'capitalB'], ['CountryA', 'IntersectionB', 'TowerE', 'capitalB'], ['CountryA', 'IntersectionB', 'BuildingD', 'capitalB']]\n",
      "current path: [('deadend', ['CountryA', 'StationC', 'deadend'])]\n",
      "current node: deadend, current path: ['CountryA', 'StationC', 'deadend']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategic_count('/Users/hanyuwu/Study/IT5001/PE/mapfile1.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it5001-xvMLlpdx-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
